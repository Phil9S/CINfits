---
title: "ML"
output: html_document
date: "2024-03-04"
---

```{r libs}
library(CINfits)
library(tidymodels)
library(glmnet)
library(ranger)
library(vip)
library(xgboost)
```

```{r ext}
## set cores for parallel compute
cores <- parallel::detectCores()
cores <- round(cores*0.8)

# Set seed
set.seed(0990)
```

```{r data}
## Load and pre-process data
cellQC <- read.table("britroc_multifit_meta.tsv",header = T,sep = "\t") %>% 
    tidyr::drop_na() %>%
    dplyr::select(-grid_ploidy) %>%
    dplyr::rename(purity = grid_purity) %>%
    dplyr::mutate(use = factor(use))

cellQcLong <- cellQC %>% 
                tidyr::pivot_longer(cols = -c(1,ncol(.)),names_to = "features")
```

```{r datapre}
## Data preview
dim(cellQC)
head(cellQC)
```

```{r plots}
ggplot(cellQcLong,aes(log(value + .Machine$double.eps),colour=use)) +
    geom_density() +
    facet_wrap(. ~ features,scales = "free") +
    theme_bw()
```

```{r datasplit}
## Perform data split using 70/20/10 split and stratified sampling to balance outcome class
dataTrainTest <- splitFittingData(cellQC,prop = 0.7,strata = "use")
dataSplit <- dataTrainTest$dataSplit

## Set training and test data sets
trainingData <- dataTrainTest$trainingData
testingData <- dataTrainTest$testingData
```

```{r outcomeBalance}
## Check class balance
table(trainingData$use,dnn = "training") / sum(table(trainingData$use))
table(testingData$use,dnn = "testing") / sum(table(testingData$use))
```

## correlated predictors

```{r corr}
corrMat <- cor(as.matrix(cellQC[,c(2:7)]),method = "spearman")
testRes = corrplot::cor.mtest(as.matrix(cellQC[,c(2:7)]),method = "spearman", conf.level = 0.95)
corrplot::corrplot(corr = corrMat,p.mat = testRes$p, method = 'number',type="upper")
```

```{r setmodelreceipe}
## Set recipe for model
# update sample column to be ID rather than predictor
modelRecipeCV <- makeModelRecipe(data = trainingData,folds = 10,strata = "use")
modelRecipe <- modelRecipeCV$recipe

summary(modelRecipe)
```

## Set cross-fold validation

```{r CVfolds}
## Set number of folds for cross-validation in training set
folds <- modelRecipeCV$cv
```

## set optimisation metric

```{r optmetric}
opt_metric <- "pr_auc"
```

## RBF SVM

```{r svmModel}
#set RBF svm
final_linsvm_res <- fitSVM(data = dataSplit,
                           model = modelRecipe,
                           folds = folds,
                           metric = opt_metric)
```

## logistic regression

```{r lgModel}
## Set logistic regression with glmnet engine/function
final_lr_res <- fitGLMLogisticRegression(data = dataSplit,
                                         model = modelRecipe,
                                         folds = folds,
                                         mixture = 0.5,
                                         metric = opt_metric)
```

## Random forest

```{r rfModel}
## Set randomforest
final_rf_res <- fitRandomForest(data = dataSplit,
                                model = modelRecipe,
                                folds = folds,
                                metric = opt_metric,
                                importance = "impurity",
                                trees = 100)
```

### xbg

```{r setxgbt}
final_xgb_res <- fitXGBtree(data = dataSplit,
                            model = modelRecipe,
                            folds = folds,
                            metric = opt_metric,
                            trees = 100)
```

## Compare models

```{r compare_models}
models <- list(final_lr_res,final_linsvm_res,final_xgb_res,final_rf_res)

modelMetrics <- collateModelMetrics(models = models)
modelROC <- collateModelRoc(models = models)
```

```{r plot_models}
ggplot(modelMetrics,aes(.metric,.estimate,fill=model)) +
        geom_col(position = "dodge") +
        facet_wrap(.metric ~ .,scales = "free_x",nrow = 1) +
        theme_bw() + theme(legend.position = "bottom")

ggplot(modelROC,aes(x = 1 - specificity, y = sensitivity, col = model)) + 
        geom_path(lwd = 1.5, alpha = 0.8) +
        geom_abline(lty = 3) + 
        coord_equal() + 
        theme_bw()

modelMetrics %>%
    select(-.estimator) %>%
    pivot_wider(names_from = ".metric",id_cols = "model",values_from = ".estimate") %>%
    arrange(desc(f_meas))
```

```{r explore borders}
rf_table <- final_rf_res %>%
                collect_predictions() %>%
                mutate(failed = .pred_class != use) %>%
                group_by(.row) %>%
                mutate(prob = max(.pred_FALSE,.pred_TRUE))

ggplot(rf_table) +
    geom_density(aes(prob,color=failed))

plot(density(rf_table$.pred_FALSE))
```

```{r session}
sessionInfo()
```
