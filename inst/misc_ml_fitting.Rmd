---
title: "ML"
output: html_document
date: "2024-03-04"
---

```{r libs}
library(CINfits)
library(tidymodels)
library(glmnet)
library(ranger)
library(vip)
library(xgboost)
```

```{r ext}
## set cores for parallel compute
cores <- parallel::detectCores()
cores <- round(cores*0.8)
```

```{r data}
## Load and pre-process data
cellQC <- data.table::fread("cellLine_fit_qc_table.tsv",header = T,sep = "\t") %>%
            dplyr::select(-notes) %>%
            tidyr::drop_na() %>%
            dplyr::mutate(use = factor(use))

cellQcLong <- cellQC %>% 
                tidyr::pivot_longer(cols = 2:6,names_to = "features")
```

```{r datapre}
## Data preview
dim(cellQC)
head(cellQC)
```

```{r plots}
ggplot(cellQcLong,aes(use,value,colour=use)) +
    geom_boxplot() +
    facet_wrap(. ~ features,scales = "free") +
    theme_bw()

ggplot(cellQcLong,aes(value,colour=use)) +
    geom_density() +
    facet_wrap(. ~ features,scales = "free") +
    theme_bw()
```

```{r datasplit}
# Set seed
set.seed(0990)

## Perform data split using 70/20/10 split and stratified sampling to balance outcome class
dataTrainTest <- splitFittingData(cellQC,prop = 0.7,strata = "use")
dataSplit <- dataTrainTest$dataSplit

## Set training and test data sets
trainingData <- dataTrainTest$trainingData
testingData <- dataTrainTest$testingData
```

```{r outcomeBalance}
## Check class balance
table(trainingData$use,dnn = "training") / sum(table(trainingData$use))
table(testingData$use,dnn = "testing") / sum(table(testingData$use))
```

## correlated predictors

```{r corr}
corrMat <- cor(as.matrix(cellQC[,c(2:6)]),method = "spearman")
testRes = corrplot::cor.mtest(as.matrix(cellQC[,c(2:6)]),method = "spearman", conf.level = 0.95)
corrplot::corrplot(corr = corrMat,p.mat = testRes$p, method = 'number',type="upper")
```

```{r setmodelreceipe}
## Set recipe for model
# update sample column to be ID rather than predictor
modelRecipe <- recipe(use ~ .,data = trainingData) %>%
                update_role(sample,new_role = "ID") %>%
                step_zv(all_predictors()) %>%
                step_corr(all_predictors())
    
summary(modelRecipe)
```

## Set cross-fold validation

```{r CVfolds}
## Set number of folds for cross-validation in training set
folds <- vfold_cv(trainingData, v = 10,strata = "use")
```

## RBF SVM

```{r svmModel}
#set RBF svm
linsvm_res_final <- fitSVM(data = dataSplit,model = modelRecipe,folds = folds,metric = "accuracy")
collect_metrics(linsvm_res_final)
```

```{r svmpred}
linsv_auc <- linsvm_res_final %>%
  collect_predictions() %>% 
  roc_curve(use, .pred_FALSE) %>% 
  mutate(model = "SVM (RBF)")
```

```{r modelPerfsvm}
linsvm_res_final %>% 
    collect_predictions() %>% 
    roc_curve(use, .pred_FALSE) %>% 
    autoplot()
```

## logistic regression

```{r lgModel}
## Set logistic regression with glmnet engine/function
lr_res_final <- fitGLMLogisticRegression(data = dataSplit,model = modelRecipe,folds = folds,mixture = 0.5,metric = "accuracy")
collect_metrics(lr_res_final)
```

```{r lgpred}
lr_auc <- lr_res_final %>%
  collect_predictions() %>% 
  roc_curve(use, .pred_FALSE) %>% 
  mutate(model = "Logistic Regression")
```

```{r modelPerflg}
lr_res_final %>%
    extract_fit_parsnip() %>% 
    vip(num_features = 20) +
    theme_bw()

lr_res_final %>% 
    collect_predictions() %>% 
    roc_curve(use, .pred_FALSE) %>% 
    autoplot()
```

## Random forest

```{r rfModel}
## Set logistic regression using glm engine/function
final_rf_res <- fitRandomForest(data = dataSplit,model = modelRecipe,folds = folds,metric = "accuracy",importance = "impurity",trees = 1000)
collect_metrics(final_rf_res)
```

```{r predrf}
rf_auc <- final_rf_res %>%
  collect_predictions()  %>%
  roc_curve(use, .pred_FALSE) %>%
  mutate(model = "random forest")
```

```{r modelPerfRF}
final_rf_res %>%
    extract_fit_parsnip() %>% 
    vip(num_features = 20) +
    theme_bw()

final_rf_res %>% 
    collect_predictions() %>% 
    roc_curve(use, .pred_FALSE) %>% 
    autoplot()
```

### xbg

```{r setxgbt}
final_xgb_res <- fitXGBtree(data = dataSplit,model = modelRecipe,folds = folds,metric = "accuracy",trees = 1000)
collect_metrics(final_xgb_res)
```

```{r predxgb}
bt_auc <- final_xgb_res %>%
  collect_predictions()  %>%
  roc_curve(use, .pred_FALSE) %>%
  mutate(model = "boosted trees (xgb)")
```

```{r modelPerfxgb}
final_xgb_res %>%
    extract_fit_parsnip() %>% 
    vip(num_features = 20) +
    theme_bw()

final_xgb_res %>% 
    collect_predictions() %>% 
    roc_curve(use, .pred_FALSE) %>% 
    autoplot()
```

## Compare models

```{r compare}
metrics <- metric_set(precision,accuracy,recall,f_meas,roc_auc)

lr_metrics <- lr_res_final %>%
    collect_predictions() %>%
    metrics(truth = use,estimate = .pred_class,.pred_FALSE) %>%
    mutate(model = "logistic regression")

linsvm_metrics <- linsvm_res_final %>%
    collect_predictions() %>%
    metrics(truth = use,estimate = .pred_class,.pred_FALSE) %>%
    mutate(model = "SVM (RBF)")

rf_metrics <- final_rf_res %>%
    collect_predictions() %>%
    metrics(truth = use,estimate = .pred_class,.pred_FALSE) %>%
    mutate(model = "random forest")

xgb_metrics <- final_xgb_res %>%
    collect_predictions() %>%
    metrics(truth = use,estimate = .pred_class,.pred_FALSE) %>%
    mutate(model = "boosted tree (xgb)")

bind_rows(lr_metrics,linsvm_metrics,rf_metrics,xgb_metrics) %>%
    ggplot(aes(.metric,.estimate,fill=model)) +
        geom_col(position = "dodge") +
        facet_wrap(.metric ~ .,scales = "free_x",nrow = 1) +
        scale_fill_viridis_d(option = "plasma", end = .6) +
        theme_bw() + theme(legend.position = "bottom")

bind_rows(rf_auc,linsv_auc,lr_auc,bt_auc) %>% 
    ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
        geom_path(lwd = 1.5, alpha = 0.8) +
        geom_abline(lty = 3) + 
        coord_equal() + 
        scale_color_viridis_d(option = "plasma", end = .6) +
        theme_bw()

bind_rows(lr_metrics,linsvm_metrics,rf_metrics,xgb_metrics) %>%
    select(-.estimator) %>%
    pivot_wider(names_from = ".metric",id_cols = "model",values_from = ".estimate") %>%
    arrange(desc(recall))
```

```{r session}
sessionInfo()
```
